mode: fp16_multi_pretrain
model: BERT

data_path: data/Amazon
pretrain_file: amazon_laptops_preprocess_pretrain.pkl
model_path: results/Amazon
#model_path: results/YELP_Amazon

num_workers_per_loader: 2

seed: 42
#batch_size: 16
batch_size: 32
dropout: 0.1
epoch: 8
report_frequency: 200
save_frequency: 400

decoder_heads: 6
decoder_layers: 6
decoder_hidden: 768
decoder_ff: 2048
decoder_dropout: 0.2
share_emb: True

optimizer: adamw
lambda_scl: 2.0
lambda_map: 1.0
lambda_rr: 1.0
learning_rate: 0.00005
learning_rate_bert: 0.00005
weight_decay: 0.00005
warm_up: 20000
grad_norm: 5.0

ckpt: '/Users/jordanharris/SCAPT-ABSA/checkpoints/restaurants_BERT/last.ckpt'
state_dict: '/Users/jordanharris/SCAPT-ABSA/results/BERT_restaurants.pt'

#  '/Users/jordanharris/SCAPT-ABSA/results/restaurants/BERT_0714051910/epoch_0_step_112_acc_0.8696_f1_0.7974_loss_0.5574.pt'


#dec_state_dict: '/Users/jordanharris/SCAPT-ABSA/results/YELP_Amazon/BERT_0703195220/epoch_4_step_5198_decoder.pt'
#gen_state_dict: '/Users/jordanharris/SCAPT-ABSA/results/YELP_Amazon/BERT_0703195220/epoch_4_step_5198_generator.pt'
